我的要求是：用python编写代码，使得我能用api_key来进行gpt接口的调用。
chat函数如下：
def chat4(prompt, temperature=0):
    import openai
    openai.api_key = OPENAI_API_KEY
    if isinstance(prompt, list):
        messages = prompt
    else:
        messages = [{"role": "user", "content": prompt}]

    retry_count = 0  # 计数器
    while True:
        try:
            start_time = time.time()  # 记录开始时间
            completion = openai.ChatCompletion.create(
                model="gpt-3.5-turbo-16k",
                messages=messages,
                temperature=temperature
            )
            print(f"API call completed in {time.time() - start_time} seconds.")  # 打印API调用用时
            break
        except Exception as e:
            if str(e).startswith("This model's maximum context length is"):
                raise e
            if retry_count >= 5: # 如果尝试了5次都失败，那么跳过这个消息
                print(f"Failed to process prompt after  retries: {prompt}")
                return None
            retry_count += 1  # 增加计数器
            print(f"API call failed, retrying in 1 second. ({retry_count}/5)")
            time.sleep(1)  # 增加延迟时间

    answer = completion.choices[0].message['content']
    return answer

我需要读取的文件是.json文件，对文件的保存类似于该代码：
def process_file(filename: str):
    # 读取json文件
    with open(filename, 'r') as f:
        data = json.load(f)

    # 找出所有没有被处理的数据
    unprocessed_data = [item for item in data if "output" not in item]

    # 按照每20个input进行处理
    for i in tqdm(range(0, len(unprocessed_data), 20), desc="Processing"):
        # 获取下一批需要处理的数据
        batch = unprocessed_data[i:i + 20]
        input_prompts = [item["input"] for item in batch]

        # 使用task_scheduler函数处理这些数据
        output = task_scheduler(input_prompts)

        # 更新json数据
        for item, output_str in zip(batch, output):
            item["output"] = output_str

        # 在原始数据中更新已处理的数据
        for item in data:
            if "output" not in item:
                for processed_item in batch:
                    if item["input"] == processed_item["input"]:
                        item["output"] = processed_item["output"]
                        break

        # 将更新后的数据立即写回文件
        with open(filename, 'w') as f:
            json.dump(data, f, indent=4)

现在需要做的是读取文件夹中的某个json文件，将文件中的input字段内容作为gpt的输入内容，output保存gpt的输出内容。
请你撰写这样的代码，使得我能实现这个功能。


